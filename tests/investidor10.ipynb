{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d594d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70257ed1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from fbpyutils import file as FU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARALLELIZE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS4_PARSER = 'lxml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d87f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIIS_COM_URL = 'https://investidor10.com.br/fiis/dividendos/'\n",
    "FIIS_PAYMENT_URL = 'https://investidor10.com.br/fiis/dividendos/data_pgto/'\n",
    "FIIS_DY_DETAILS_URL = 'https://investidor10.com.br/fiis/rankings/maior-dividend-yield/'\n",
    "IFIX_PAGE_URL = \"https://fiis.com.br/ifix/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTURE_DATE = datetime.now().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f42aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tag_to_str(x):\n",
    "    \"\"\"\n",
    "    Convert a given tag object to a string representation.\n",
    "     Args:\n",
    "        x (Tag): The tag object to convert.\n",
    "     Returns:\n",
    "        str: The modified text representation of the tag object.\n",
    "     Description:\n",
    "        This lambda function takes a tag object as input and converts it to a string representation.\n",
    "        It removes any newline characters from the text and removes leading and trailing whitespace.\n",
    "        The resulting modified text is then returned as a string.\n",
    "    \"\"\"\n",
    "    return x.text.replace('\\n', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _any_to_number(x):\n",
    "    \"\"\"\n",
    "    Convert a given value to a numeric representation.\n",
    "     Args:\n",
    "        x (any): The value to convert.\n",
    "     Returns:\n",
    "        float or None: The numeric representation of the value, or None if the value is '-'.\n",
    "     Description:\n",
    "        This lambda function takes a value as input and converts it to a numeric representation.\n",
    "        If the value is '-', it returns None.\n",
    "        Otherwise, it performs the following transformations on the value:\n",
    "        - Split the value by spaces and take the last element.\n",
    "        - Replace any occurrence of '.' with an empty string.\n",
    "        - Replace any occurrence of ',' with '.'.\n",
    "        - Replace any occurrence of '%' with an empty string.\n",
    "        The resulting modified value is then converted to a float and returned.\n",
    "    \"\"\"\n",
    "    return None if str(x) == '-' \\\n",
    "        else float(str(x).split(' ')[-1].replace('.','').replace(',','.').replace('%',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fff553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_fii_all_payment_data(fiis_page_url):\n",
    "    \"\"\"\n",
    "    Retrieve and process payment data for FIIs (Fundos de Investimento Imobiliário).\n",
    "     Args:\n",
    "        fiis_page_url (str): The URL of the FIIs page to scrape.\n",
    "     Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the payment data for FIIs.\n",
    "     Raises:\n",
    "        SystemError: If the HTTP request to the FIIs page returns a non-200 status code.\n",
    "     Description:\n",
    "        This function retrieves payment data for FIIs from a given webpage URL. It scrapes the webpage using the requests library\n",
    "            and parses the HTML content using BeautifulSoup.\n",
    "        The function starts by checking the HTTP status code of the webpage. If the status code is not 200, it raises a \n",
    "            SystemError with an appropriate message.\n",
    "        It then initializes an empty list to store the payment data and defines a list of month names in Portuguese.\n",
    "        The current year is obtained using the datetime module.\n",
    "        The function iterates over each month group of payments on the webpage and extracts the year from the month group's header\n",
    "            if available.\n",
    "        For each payment card within a month group, it retrieves the payment day, month, and other payment details.\n",
    "        The function then extracts the FII ticker, details URL, name, payment amount, and payment date from each payment row within\n",
    "            a payment card.\n",
    "        The payment date is constructed using the extracted year, month, and day.\n",
    "        The extracted data is appended to the 'data' list.\n",
    "        Finally, the 'data' list is used to create a pandas DataFrame with appropriate column names.\n",
    "        The resulting DataFrame is returned as the output of the function.\n",
    "    \"\"\"\n",
    "    fiis_page = requests.get(fiis_page_url, headers=HEADERS)\n",
    "    \n",
    "    if fiis_page.status_code != 200:\n",
    "        raise SystemError(f'Http Error not 200: {fiis_page.status_code}')\n",
    "    \n",
    "    P = BeautifulSoup(fiis_page.text, BS4_PARSER)\n",
    "\n",
    "    data = []\n",
    "    months = [\n",
    "        'Janeiro', 'Fevereiro', 'Março', 'Abril', 'Maio', 'Junho', \n",
    "        'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro'\n",
    "    ]\n",
    "    \n",
    "    fii_pmt_year = datetime.now().year\n",
    "    for fii_month_group in P.find('div', attrs={'id': 'list-content'}).findAll('div', attrs=({'class': 'month-group-payment'})):\n",
    "        if fii_month_group.find('h3', attrs={'class': 'month-name'}):\n",
    "            fii_pmt_year = int(_tag_to_str(fii_month_group.find('h3', attrs={'class': 'month-name'})).split(' ')[-1])\n",
    "        \n",
    "        for payment_card in fii_month_group.findAll('div', attrs={'class': 'payment-card'}):\n",
    "            fii_pmt_day = int(_tag_to_str(payment_card.find('div', attrs={'class': 'payment-day'})))\n",
    "            fii_pmt_month = months.index(_tag_to_str(payment_card.find('div', attrs={'class': 'text-center'}))) + 1\n",
    "            \n",
    "            for fii_payment in payment_card.find_all('div', attrs={'class': 'row payment-row'}):\n",
    "                fii_ticker = _tag_to_str(fii_payment.find('a', attrs={'class': 'fii-ticker'}, href=True))\n",
    "                fii_details = fii_payment.find('a', attrs={'class': 'fii-ticker'}, href=True)['href']    \n",
    "                fii_name = _tag_to_str(fii_payment.find_all('h4')[-1])\n",
    "\n",
    "                p1, p2 = fii_payment.find_all('p')\n",
    "                fii_pmt = float(_tag_to_str(p1).split(' ')[-1])\n",
    "                fii_com_date = datetime.strptime(p2.text.split(' ')[-1], '%d/%m/%Y')\n",
    "\n",
    "                fii_pmt_date = datetime(fii_pmt_year, fii_pmt_month, fii_pmt_day).date()\n",
    "\n",
    "                data.append([\n",
    "                    fii_ticker, fii_name, fii_pmt, fii_com_date, fii_pmt_date, fii_details, CAPTURE_DATE\n",
    "                ])\n",
    " \n",
    "    fii_payment_dates = pd.DataFrame(\n",
    "        data, columns=['ticker', 'name', 'payment', 'com_date', 'payment_date', 'details', 'reference_date']\n",
    "    )\n",
    "\n",
    "    return fii_payment_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c149888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_fii_payment_data(fiis_page_url, type):\n",
    "    \"\"\"\n",
    "    Retrieves FII payment data from a given webpage URL.\n",
    "     Parameters:\n",
    "        - fiis_page_url (str): The URL of the page containing the FII payment data.\n",
    "        - type (str): The type of payment ('com' or 'payment').\n",
    "     Returns:\n",
    "        - fii_payment_dates (DataFrame): A pandas DataFrame containing the FII payment data.\n",
    "     Raises:\n",
    "        - TypeError: If the provided payment type is not valid.\n",
    "     Overall:\n",
    "        This function takes a URL and payment type as input, fetches the FII payment data from the webpage,\n",
    "        extracts relevant information, and returns it as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if not type in ('com', 'payment'):\n",
    "        raise TypeError('Invalid payment type')\n",
    "\n",
    "    fiis_page = requests.get(fiis_page_url, headers=HEADERS)\n",
    "\n",
    "    S = BeautifulSoup(fiis_page.text, BS4_PARSER)\n",
    "    fii_payment_rows = S.find_all('div', attrs={'class': 'row payment-row'})\n",
    "\n",
    "    fii_payments = []\n",
    "    for fii_payment in fii_payment_rows:\n",
    "        fii_ticker = _tag_to_str(fii_payment.find('a', attrs={'class': 'fii-ticker'}, href=True))\n",
    "        fii_details = fii_payment.find('a', attrs={'class': 'fii-ticker'}, href=True)['href']    \n",
    "        fii_name = _tag_to_str(fii_payment.find_all('h4')[-1])\n",
    "\n",
    "        p1, p2 = fii_payment.find_all('p')\n",
    "        fii_payment = float(_tag_to_str(p1).split(' ')[-1])\n",
    "\n",
    "        fii_payment_date = datetime.strptime(p2.text.split(' ')[-1], '%d/%m/%Y')\n",
    "\n",
    "        fii_payments.append((fii_ticker, fii_name, fii_payment, fii_payment_date, fii_details, CAPTURE_DATE))\n",
    "\n",
    "    fii_payment_dates = pd.DataFrame(\n",
    "        fii_payments, columns=['ticker', 'name', 'payment', f'{type}_date', 'details', 'reference_date']\n",
    "    )\n",
    "\n",
    "    return fii_payment_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd29ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ifix_data(ifix_page_url):\n",
    "    \"\"\"\n",
    "    Retrieves iFIX data from a given webpage URL.\n",
    "    Parameters:\n",
    "        - ifix_page_url (str): The URL of the page containing the iFIX data.\n",
    "     Returns:\n",
    "        - ifix_data (DataFrame): A pandas DataFrame containing the iFIX data.\n",
    "    Overall:\n",
    "        This function takes a URL as input, fetches the iFIX data from the webpage, extracts relevant\n",
    "        information, and returns it as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    ifix_page = requests.get(ifix_page_url, headers=HEADERS)\n",
    "\n",
    "    I = BeautifulSoup(ifix_page.text, BS4_PARSER)\n",
    "    ifix_table_body = I.find('tbody')\n",
    "\n",
    "    ifix = []\n",
    "    df_columns = ['ticker', 'title', 'share', 'details', 'reference_date']\n",
    "    parse_float = lambda x: float(x.replace(',', '.').replace('%', ''))\n",
    "\n",
    "    for t in ifix_table_body.children:\n",
    "        if type(t) == Tag:\n",
    "            ifix_share = t.find('td', attrs={'class': 'fixed-column'})\n",
    "            ifix_title = t.find('p')\n",
    "            ifix_ticker = t.find('a')\n",
    "            if all([ifix_share, ifix_title, ifix_ticker]):\n",
    "                ifix_details = ifix_ticker.get('href')\n",
    "                if type(ifix_details) == Tag:\n",
    "                    ifix_details = _tag_to_str(ifix_details)\n",
    "                ifix.append((\n",
    "                    _tag_to_str(ifix_ticker), \n",
    "                    _tag_to_str(ifix_title), \n",
    "                    parse_float(_tag_to_str(ifix_share)), \n",
    "                    ifix_details, \n",
    "                    CAPTURE_DATE\n",
    "                ))\n",
    "\n",
    "    return pd.DataFrame(ifix, columns=df_columns[0:len(ifix[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc30c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_fii_dy_ranking_data(fii_dy_details_url):\n",
    "    \"\"\"\n",
    "    Retrieves dividend yield ranking data for FIIs (Foreign Institutional Investors).\n",
    "     Args:\n",
    "        fii_dy_details_url (str): The URL of the webpage containing the FII dividend yield details.\n",
    "     Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the extracted dividend yield ranking data.\n",
    "     Purpose:\n",
    "        This function provides a convenient way to retrieve and process dividend yield ranking data for FIIs from a\n",
    "        given webpage URL. The extracted data can be further analyzed or used for various purposes.\n",
    "    \"\"\"\n",
    "    dy_page = requests.get(fii_dy_details_url, headers=HEADERS)\n",
    "\n",
    "    Y = BeautifulSoup(dy_page.text, BS4_PARSER)\n",
    "\n",
    "    dy_columns = [\n",
    "        'ticker', 'dy_current', 'p_vp', 'daily_liquidity', \n",
    "        'daily_liquidity_unit', 'net_worth', 'net_worth_unit', \n",
    "        'var_last_12_months', 'fund_type', 'segment', 'reference_date'\n",
    "    ]\n",
    "\n",
    "    dy_ranking_table = Y.find('table', id='rankigns')\n",
    "    dy_rows = dy_ranking_table.findAll('tr')\n",
    "\n",
    "    dy_data = []\n",
    "    for dy_row in dy_rows[1:]:\n",
    "        dy_ticker, dy_current, dy_p_vp, dy_daily_liquidity, dy_net_worth, dy_ytd_var, dy_fund_type, dy_segment = dy_row.findAll('td')\n",
    "\n",
    "        float_from_comma_str = lambda x: float(str(x).replace(',', '~').replace('.', '').replace('~', '.')) \n",
    "\n",
    "        dy_ticker = _tag_to_str(dy_ticker)\n",
    "        dy_current = float(_tag_to_str(dy_current))\n",
    "        dy_p_vp = float(_tag_to_str(dy_p_vp))\n",
    "\n",
    "        dy_daily_liquidity, dy_daily_liquidity_unit = _tag_to_str(dy_daily_liquidity).split(' ')\n",
    "        dy_daily_liquidity = float_from_comma_str(dy_daily_liquidity)\n",
    "\n",
    "        dy_net_worth, dy_net_worth_unit = _tag_to_str(dy_net_worth).split(' ')\n",
    "        dy_net_worth = float_from_comma_str(dy_net_worth)\n",
    "\n",
    "        dy_ytd_var = float(_tag_to_str(dy_ytd_var))\n",
    "\n",
    "        dy_fund_type = _tag_to_str(dy_fund_type)\n",
    "        dy_segment = _tag_to_str(dy_segment)\n",
    "\n",
    "        dy_data.append((\n",
    "            dy_ticker, dy_current, dy_p_vp, dy_daily_liquidity, dy_daily_liquidity_unit, \n",
    "            dy_net_worth, dy_net_worth_unit, dy_ytd_var, dy_fund_type, dy_segment, CAPTURE_DATE\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(dy_data, columns=dy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_fii_indicators(info, sleep=None):\n",
    "    \"\"\"\n",
    "    Retrieves FII (Fundo de Investimento Imobiliário) indicators from a given URL.\n",
    "     Args:\n",
    "        info (tuple): A tuple containing information about FII.\n",
    "            - If len(info) == 4, the tuple should contain (fii_ticker, fii_details_url, capture_date, sleep).\n",
    "            - If len(info) != 4, the tuple should contain (fii_ticker, fii_details_url, capture_date).\n",
    "        sleep (float, optional): The sleep time in seconds between requests. Defaults to None.\n",
    "     Returns:\n",
    "        dict: A dictionary containing FII indicators.\n",
    "            - The dictionary contains the following keys:\n",
    "                - 'PAPEL': The FII ticker.\n",
    "                - 'URL': The FII details URL.\n",
    "                - 'DATA_REFERÊNCIA': The capture date.\n",
    "                - 'COTAÇÃO': The FII price.\n",
    "                - 'DATA_COTAÇÃO': The FII price date.\n",
    "                - Other FII indicators retrieved from the webpage.\n",
    "     Raises:\n",
    "        SystemError: If the HTTP status code is not 200.\n",
    "     Notes:\n",
    "        - This function uses the requests library to retrieve the webpage content.\n",
    "        - It also uses BeautifulSoup for parsing the HTML content.\n",
    "        - The function expects the HTML structure of the webpage to be consistent.\n",
    "        - If the sleep argument is provided, the function will sleep for the specified time before returning.\n",
    "     Example:\n",
    "        info = ('FII_TICKER', 'https://example.com/fii_details', '2022-01-01')\n",
    "        indicators = _get_fii_indicators(info, sleep=0.5)\n",
    "        print(indicators)\n",
    "        # Output: {'PAPEL': 'FII_TICKER', 'URL': 'https://example.com/fii_details', 'DATA_REFERÊNCIA': '2022-01-01', ...}\n",
    "    \"\"\"\n",
    "    sleep = sleep or 0.3\n",
    "\n",
    "    try:\n",
    "        if len(info) == 4:\n",
    "            fii_ticker, fii_details_url, capture_date, sleep = info\n",
    "        else:\n",
    "            fii_ticker, fii_details_url, capture_date = info\n",
    "\n",
    "        fii_indicator = {'PAPEL': fii_ticker, 'URL': fii_details_url, 'DATA_REFERÊNCIA': capture_date}\n",
    "\n",
    "        dt_page = requests.get(fii_details_url, headers=HEADERS)\n",
    "\n",
    "        if dt_page.status_code != 200:\n",
    "            raise SystemError(f'Http Error not 200: {dt_page.status_code}')\n",
    "\n",
    "        D = BeautifulSoup(dt_page.text, BS4_PARSER)\n",
    "\n",
    "        fii_price = _any_to_number(_tag_to_str(\n",
    "            D.find('div', attrs={'class': '_card cotacao'}).find('div', attrs={'class': '_card-body'})\n",
    "        ).split(' ')[-1])\n",
    "        fii_indicator['COTAÇÃO'] = fii_price\n",
    "\n",
    "        fii_price_date = datetime.strptime(\n",
    "            D.find(\n",
    "                'div', attrs={'class': '_card cotacao'}\n",
    "            ).find(\n",
    "                'div', attrs={'class': '_card-body'}\n",
    "            ).find('i').attrs['data-content'].split(' ')[-1],\n",
    "            '%d/%m/%Y'\n",
    "        ).date()\n",
    "\n",
    "        fii_indicator['DATA_COTAÇÃO'] = fii_price_date\n",
    "        for e in D.find('div', attrs={'id': 'table-indicators'}).findAll('div', attrs={'class': 'cell'}):\n",
    "            k = _tag_to_str(e.find('div', attrs={'class': 'desc'}).find('span'))\n",
    "            v = (\n",
    "                _tag_to_str(e.find('div', attrs={'class': 'value'}).find('span')) \n",
    "            )\n",
    "\n",
    "            fii_indicator[k] = v\n",
    "\n",
    "        v = _any_to_number(fii_indicator['NUMERO DE COTISTAS'])\n",
    "        fii_indicator['NUMERO DE COTISTAS'] = None if v is None else int(v)\n",
    "\n",
    "        v = _any_to_number(fii_indicator['COTAS EMITIDAS'])\n",
    "        fii_indicator['COTAS EMITIDAS'] = None if v is None else int(v)\n",
    "        fii_indicator['VAL. PATRIMONIAL P/ COTA'] = _any_to_number(fii_indicator['VAL. PATRIMONIAL P/ COTA'].split(' ')[-1])\n",
    "\n",
    "        _, v2, v3 = fii_indicator['VALOR PATRIMONIAL'].split(' ')\n",
    "        fii_indicator['VALOR PATRIMONIAL'] = _any_to_number(v2)\n",
    "        fii_indicator['VALOR PATRIMONIAL UNIT'] = v3\n",
    "\n",
    "        fii_indicator['ÚLTIMO RENDIMENTO'] = _any_to_number(fii_indicator['ÚLTIMO RENDIMENTO'].split(' ')[-1])\n",
    "\n",
    "        fii_indicator['VACÂNCIA'] = _any_to_number(fii_indicator['VACÂNCIA'])\n",
    "\n",
    "        if sleep: time.sleep(sleep)\n",
    "        \n",
    "        return fii_indicator\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fii_daily_position(parallelize=True):\n",
    "    \"\"\"\n",
    "    Retrieves daily position of FII (Fundo de Investimento Imobiliário) by querying data from various sources and storing\n",
    "    them in an SQLite database in memory. The function then joins the queried data and returns a DataFrame containing the\n",
    "    daily position of FII.\n",
    "     Args:\n",
    "        parallelize (bool, optional): A flag to determine whether to use parallel processing. Defaults to True. \n",
    "        If True and the system has more than one CPU, the function will use multiprocessing to retrieve FII indicators.\n",
    "     Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the daily position of FII. The DataFrame contains the following\n",
    "        columns: 'payment_year', 'payment_year_month', 'payment_date', 'com_date', 'ticker', 'name', 'fund_name',\n",
    "        'fund_id', 'fund_type', 'segment', 'audience', 'mandate_type', 'term_type', 'management_type', 'admin_rate',\n",
    "        'payment', 'price', 'price_date', 'payment_price_ratio', 'ifix_share', 'dy_current', 'p_vp', 'daily_liquidity',\n",
    "        'daily_liquidity_unit', 'net_worth', 'net_worth_unit', 'var_last_12_months', 'vacancy', 'shareholders', 'shares',\n",
    "        'equity_by_share', 'equity', 'equity_unit', 'last_payment', 'reference_date'.\n",
    "     Raises:\n",
    "        Exception: If there is an error in retrieving data from the URLs or in processing the data.\n",
    "     Notes:\n",
    "        - This function uses the pandas library to read and write data from/to the SQLite database.\n",
    "        - It also uses the sqlite3 library to execute SQL queries.\n",
    "        - The function expects the URLs to return data in a specific format.\n",
    "        - If the parallelize argument is True and the system has more than one CPU, the function will use multiprocessing\n",
    "            to retrieve FII indicators. Otherwise, it will retrieve the indicators sequentially.\n",
    "     Example:\n",
    "        df = get_fii_daily_position()\n",
    "        print(df.head())\n",
    "    \"\"\"\n",
    "    PARALLELIZE = parallelize and os.cpu_count()>1\n",
    "\n",
    "    db = sqlite3.connect(':memory:')\n",
    "\n",
    "    read_sql = lambda x, y={}: pd.read_sql(x, params=y, con=db)\n",
    "\n",
    "    try:\n",
    "        _get_fii_all_payment_data(FIIS_PAYMENT_URL).to_sql('fii_payment_calendar', index=False, if_exists='replace', con=db)\n",
    "\n",
    "        _get_ifix_data(IFIX_PAGE_URL).to_sql('fii_ifix_position', con=db, index=False, if_exists='replace')\n",
    "\n",
    "        _get_fii_dy_ranking_data(FIIS_DY_DETAILS_URL).to_sql('fii_dividend_yeld_ranking', con=db, index=False, if_exists='replace')\n",
    "\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute('create index fii_payment_calendar_i01 on fii_payment_calendar (substr(payment_date, 1, 4))')\n",
    "        cursor.execute('create index fii_payment_calendar_i02 on fii_payment_calendar (payment_date, ticker)')\n",
    "        cursor.execute('create index fii_ifix_position_i01 on fii_ifix_position (ticker)')\n",
    "        cursor.execute('create index fii_dividend_yeld_ranking_i01 on fii_dividend_yeld_ranking (ticker)')\n",
    "\n",
    "        fii_info = read_sql('''\n",
    "        select distinct ticker, details\n",
    "            from fii_payment_calendar\n",
    "        ''')\n",
    "        fii_info['capture_date'] = CAPTURE_DATE\n",
    "        fii_info = tuple(fii_info.to_records(index=False))\n",
    "\n",
    "        if PARALLELIZE:\n",
    "            with Pool(os.cpu_count()) as p:\n",
    "                data = p.map(_get_fii_indicators, fii_info)\n",
    "        else:\n",
    "            data = []\n",
    "            for info in fii_info:\n",
    "                data.append(_get_fii_indicators(info))\n",
    "\n",
    "        fii_indicators_df = pd.DataFrame.from_dict(\n",
    "            [d for d in data if d]\n",
    "        )\n",
    "\n",
    "        fii_indicators_df.columns = [\n",
    "            'ticker', 'url', 'ref_date', 'price', 'price_date',\n",
    "            'fund_name', 'fund_id', 'audience', 'mandate_type', 'segment',\n",
    "            'fund_type', 'term_type', 'management_type',\n",
    "            'admin_rate', 'vacancy', 'shareholders',\n",
    "            'shares', 'equity_by_share', 'equity',\n",
    "            'last_payment', 'equity_unit'\n",
    "        ]\n",
    "\n",
    "        fii_indicators_df[[\n",
    "            'ticker', 'url', 'ref_date', 'price', 'price_date',\n",
    "            'fund_name', 'fund_id', 'audience', 'mandate_type', 'segment',\n",
    "            'fund_type', 'term_type', 'management_type',\n",
    "            'admin_rate', 'vacancy', 'shareholders',\n",
    "            'shares', 'equity_by_share', 'equity', 'equity_unit',\n",
    "            'last_payment'\n",
    "        ]].to_sql('fii_indicators', con=db, index=False, if_exists='replace')\n",
    "\n",
    "        cursor.execute('create index fii_indicators_i01 on fii_payment_calendar (ticker)')\n",
    "\n",
    "        return read_sql(f\"\"\"\n",
    "            select \n",
    "                substr(p.payment_date, 1, 4)       as payment_year,\n",
    "                substr(p.payment_date, 1, 7)       as payment_year_month,\n",
    "                substr(p.payment_date, 1, 10)      as payment_date,\n",
    "                substr(p.com_date, 1, 10)          as com_date,\n",
    "                p.ticker,\n",
    "                coalesce(f.title, p.name)          as name,\n",
    "                i.fund_name, \n",
    "                i.fund_id, \n",
    "\n",
    "                coalesce(r.fund_type, i.fund_type) as fund_type,\n",
    "                coalesce(r.segment, i.segment)     as segment,\n",
    "                i.audience, \n",
    "                i.mandate_type, \n",
    "                i.term_type, \n",
    "                i.management_type,\n",
    "                i.admin_rate,\n",
    "\n",
    "                p.payment,\n",
    "                i.price, \n",
    "                i.price_date,\n",
    "                case \n",
    "                    when i.price is not null \n",
    "                    then p.payment / i.price \n",
    "                    else null \n",
    "                end payment_price_ratio, \n",
    "\n",
    "                f.share                            as ifix_share,\n",
    "                r.dy_current,\n",
    "                r.p_vp,\n",
    "                r.daily_liquidity,\n",
    "                r.daily_liquidity_unit,\n",
    "                r.net_worth,\n",
    "                r.net_worth_unit,\n",
    "                r.var_last_12_months,\n",
    "\n",
    "                i.vacancy, \n",
    "                i.shareholders,\n",
    "                i.shares, \n",
    "                i.equity_by_share, \n",
    "                i.equity, \n",
    "                i.equity_unit,\n",
    "                i.last_payment,\n",
    "\n",
    "                p.reference_date\n",
    "            from fii_payment_calendar as p\n",
    "            left join fii_ifix_position as f \n",
    "                using (ticker)\n",
    "            left join fii_dividend_yeld_ranking as r \n",
    "                using (ticker)\n",
    "            left join fii_indicators as i\n",
    "                using (ticker)\n",
    "            where substr(p.payment_date, 1, 4) <> '9999'\n",
    "            order by payment_date, ticker\n",
    "        \"\"\")\n",
    "    finally:\n",
    "        db.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
